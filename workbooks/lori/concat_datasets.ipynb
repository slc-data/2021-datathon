{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating COSA Datasets LOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial dataset \n",
    "#air1 = pd.read_csv('med_center_air1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional dataset\n",
    "#air2 = pd.read_csv('med_center_air.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check out datatypes and nulls\n",
    "#air1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkout datatypes and nulls\n",
    "#air2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O3 is a float in air 2, need to make them both floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#air1.astype({'O3': 'float64'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#air1.astype({'O3': 'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#air1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#air1.O3 = air1.O3.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#air1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#air1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full cosa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_daily_COSA_dataframe():\n",
    "    sound_df = wrangle.wrangle_sound()\n",
    "    sound_df = sound_df.set_index('DateTime')\n",
    "    sound_df = sound_df.sort_index()\n",
    "    flood_df = wrangle.clean_flood()\n",
    "    flood_df = flood_df.set_index('datetime')\n",
    "    weather_df = wrangle.wrangle_weather()\n",
    "    air_df = wrangle.clean_air()\n",
    "    air_df.datetime = pd.to_datetime(air_df.datetime)\n",
    "    air_df = air_df.set_index('datetime')\n",
    "    air_df = air_df.sort_index()\n",
    "    weather_day_df = weather_df.resample('D', on='datetime').mean()\n",
    "    flood_day_df = flood_df.resample('D').mean()\n",
    "    sound_day_df = sound_df.resample('D').mean()\n",
    "    air_day_df = air_df.resample('D').mean().drop(columns = ['hour', 'weekday', 'CO_24hr', 'Pm_25_24hr', 'Pm_10_24hr', 'SO2', 'O3', 'NO2'])\n",
    "    air2_5 = air_df.drop(air_df.columns.difference(['Pm2_5', 'AQI_pm2_5']), 1)\n",
    "    air10 = air_df.drop(air_df.columns.difference(['Pm10', 'AQI_pm10']), 1)\n",
    "    airCO = air_df.drop(air_df.columns.difference(['CO', 'AQI_CO']), 1)\n",
    "    series2_5 = air2_5.resample('D').max().rename(columns = {'AQI_pm2_5': 'most_hazardous_pm2.5_level'})['most_hazardous_pm2.5_level']\n",
    "    series10 = air10.resample('D').max().rename(columns = {'AQI_pm10': 'most_hazardous_pm10_level'})['most_hazardous_pm10_level']\n",
    "    seriesCO = airCO.resample('D').max().rename(columns = {'AQI_CO': 'most_hazardous_CO_level'})['most_hazardous_CO_level']\n",
    "    hazards = pd.DataFrame(series2_5).join(series10).join(seriesCO)\n",
    "    df = weather_day_df.join(air_day_df).join(hazards).join(sound_day_df).join(flood_day_df)\n",
    "    df = df.round({'celsius': 2, 'farenheit': 2, 'humidity': 2, 'dewpoint_celsius': 2, 'dewpoint_farenheit': 2,\n",
    "          'pressure': 2, 'NoiseLevel_db': 2, 'sensor_to_water_feet': 2, 'sensor_to_water_meters': 2,\n",
    "          'sensor_to_ground_feet': 2, 'sensor_to_ground_meters': 2, 'flood_depth_feet': 2,\n",
    "          'flood_depth_meters': 2})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_daily_COSA_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_hours_daily_COSA_dataframe():\n",
    "    sound_df = wrangle.wrangle_sound()\n",
    "    sound_df = sound_df.set_index('DateTime')\n",
    "    sound_df = sound_df.sort_index()\n",
    "    flood_df = wrangle.clean_flood()\n",
    "    flood_df = flood_df.set_index('datetime')\n",
    "    weather_df = wrangle.wrangle_weather()\n",
    "    air_df = wrangle.clean_air()\n",
    "    air_df.datetime = pd.to_datetime(air_df.datetime)\n",
    "    air_df = air_df.set_index('datetime')\n",
    "    air_df = air_df.sort_index()\n",
    "    weather_hour_df = weather_df.resample('1H', on='datetime').mean()\n",
    "    flood_hour_df = flood_df.resample('1H').mean()\n",
    "    sound_hour_df = sound_df.resample('1H').mean()\n",
    "    air_hour_df = air_df.resample('1H').mean().drop(columns = ['hour', 'weekday', 'CO_24hr', 'Pm_25_24hr', 'Pm_10_24hr', 'SO2', 'O3', 'NO2'])\n",
    "    air2_5 = air_df.drop(air_df.columns.difference(['Pm2_5', 'AQI_pm2_5']), 1)\n",
    "    air10 = air_df.drop(air_df.columns.difference(['Pm10', 'AQI_pm10']), 1)\n",
    "    airCO = air_df.drop(air_df.columns.difference(['CO', 'AQI_CO']), 1)\n",
    "    series2_5 = air2_5.resample('1H').max().rename(columns = {'AQI_pm2_5': 'most_hazardous_pm2.5_level'})['most_hazardous_pm2.5_level']\n",
    "    series10 = air10.resample('1H').max().rename(columns = {'AQI_pm10': 'most_hazardous_pm10_level'})['most_hazardous_pm10_level']\n",
    "    seriesCO = airCO.resample('1H').max().rename(columns = {'AQI_CO': 'most_hazardous_CO_level'})['most_hazardous_CO_level']\n",
    "    hazards = pd.DataFrame(series2_5).join(series10).join(seriesCO)\n",
    "    df = weather_hour_df.join(air_hour_df).join(hazards).join(sound_hour_df).join(flood_hour_df)\n",
    "    df = df.round({'celsius': 2, 'farenheit': 2, 'humidity': 2, 'dewpoint_celsius': 2, 'dewpoint_farenheit': 2,\n",
    "          'pressure': 2, 'NoiseLevel_db': 2, 'sensor_to_water_feet': 2, 'sensor_to_water_meters': 2,\n",
    "          'sensor_to_ground_feet': 2, 'sensor_to_ground_meters': 2, 'flood_depth_feet': 2,\n",
    "          'flood_depth_meters': 2})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_df = all_hours_daily_COSA_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(20, 7))\n",
    "plt.style.use('tableau-colorblind10')\n",
    "plt.rc('font', size=16)\n",
    "plt.plot(hour_df.index, hour_df.farenheit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hour_df.to_csv('hours.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly roll up\n",
    "def all_months_daily_COSA_dataframe():\n",
    "    sound_df = wrangle.wrangle_sound()\n",
    "    sound_df = sound_df.set_index('DateTime')\n",
    "    sound_df = sound_df.sort_index()\n",
    "    flood_df = wrangle.clean_flood()\n",
    "    flood_df = flood_df.set_index('datetime')\n",
    "    weather_df = wrangle.wrangle_weather()\n",
    "    air_df = wrangle.clean_air()\n",
    "    air_df.datetime = pd.to_datetime(air_df.datetime)\n",
    "    air_df = air_df.set_index('datetime')\n",
    "    air_df = air_df.sort_index()\n",
    "    weather_month_df = weather_df.resample('M', on='datetime').mean()\n",
    "    flood_month_df = flood_df.resample('M').mean()\n",
    "    sound_month_df = sound_df.resample('M').mean()\n",
    "    air_month_df = air_df.resample('M').mean().drop(columns = ['hour', 'weekday', 'CO_24hr', 'Pm_25_24hr', 'Pm_10_24hr'])\n",
    "    air2_5 = air_df.drop(air_df.columns.difference(['Pm2_5', 'AQI_pm2_5']), 1)\n",
    "    air10 = air_df.drop(air_df.columns.difference(['Pm10', 'AQI_pm10']), 1)\n",
    "    airCO = air_df.drop(air_df.columns.difference(['CO', 'AQI_CO']), 1)\n",
    "    series2_5 = air2_5.resample('M').max().rename(columns = {'AQI_pm2_5': 'most_hazardous_pm2.5_level'})['most_hazardous_pm2.5_level']\n",
    "    series10 = air10.resample('M').max().rename(columns = {'AQI_pm10': 'most_hazardous_pm10_level'})['most_hazardous_pm10_level']\n",
    "    seriesCO = airCO.resample('M').max().rename(columns = {'AQI_CO': 'most_hazardous_CO_level'})['most_hazardous_CO_level']\n",
    "    hazards = pd.DataFrame(series2_5).join(series10).join(seriesCO)\n",
    "    df = weather_month_df.join(air_month_df).join(hazards).join(sound_month_df).join(flood_month_df)\n",
    "    df = df.round({'celsius': 2, 'farenheit': 2, 'humidity': 2, 'dewpoint_celsius': 2, 'dewpoint_farenheit': 2,\n",
    "          'pressure': 2, 'NoiseLevel_db': 2, 'sensor_to_water_feet': 2, 'sensor_to_water_meters': 2,\n",
    "          'sensor_to_ground_feet': 2, 'sensor_to_ground_meters': 2, 'flood_depth_feet': 2,\n",
    "          'flood_depth_meters': 2})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = all_months_daily_COSA_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = wrangle.wrangle_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saws = wrangle.wrangle_saws()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saws.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saws.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv for exploration in tableauy\n",
    "#saws.to_csv('clean_saws.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangle SAWS\n",
    "def wrangle_saws():\n",
    "    '''This function will drop unnecessary columns, \n",
    "    create a 'location' using data acquired from \n",
    "    other columns, and melt the data to make month year column'''\n",
    "    # Reads the csv\n",
    "    saws = pd.read_csv('med_center_saws.csv')\n",
    "    # Removes NaN values from 'Prefix' and 'Suffix' column for concatenation in 'location'\n",
    "    saws['Prefix'] = saws.Prefix.fillna(value = '')\n",
    "    saws['Suffix'] = saws.Suffix.fillna(value = '')\n",
    "    # Concatenating columns together for specific location\n",
    "    saws['location'] = saws['Prefix'] + ' ' + saws['Service Location'] + ' ' + saws['Suffix']\n",
    "    # Stripping any extra whitespace\n",
    "    saws['location'] = saws.location.str.strip()\n",
    "    saws = saws.drop(columns=['Unnamed: 0', 'Prefix', 'Suffix', 'Service Location'])\n",
    "    saws = saws.melt(id_vars=['Record #', 'ZIP Code', 'location'], \n",
    "              var_name='Month & Year', value_name='Gallons Consumed')\n",
    "    saws = saws.set_index('Record #')\n",
    "    saws = saws.fillna(0)\n",
    "    saws = saws.rename(columns={\"ZIP Code\": \"zipcode\", 'Month & Year':'year_month', \n",
    "                                'Gallons Consumed':'gallons_consumed'})\n",
    "    # replace * with 0\n",
    "    saws = saws.replace(to_replace='*', value=0)\n",
    "    # change data type\n",
    "    saws['gallons_consumed'] = saws['gallons_consumed'].astype(int)\n",
    "    return saws\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saws.year_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pd.to_datetime(saws.year_month)\n",
    "except ValueError as e:\n",
    "    print('ValueError', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saws.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saws['year_month'] = '01-20' + saws['year_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saws.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saws.year_month = pd.to_datetime(saws.year_month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saws.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(saws.year_month.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saws.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dates(saws):\n",
    "    '''\n",
    "    Function to fix year month column into\n",
    "    datetime.  Adds arbitraty day. but keeps \n",
    "    the same month and year.  \n",
    "    '''\n",
    "    saws['datetime'] = '01-20' + saws['year_month']\n",
    "    saws.datetime = pd.to_datetime(saws.datetime)\n",
    "    return saws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saws = fix_dates(saws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saws.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saws.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dates(saws):\n",
    "    '''\n",
    "    Function to fix year month column into\n",
    "    datetime.  Adds arbitraty day. but keeps \n",
    "    the same month and year.  \n",
    "    '''\n",
    "    saws['datetime'] = '01-20' + saws['year_month']\n",
    "    saws.datetime = pd.to_datetime(saws.datetime)\n",
    "    return saws\n",
    "\n",
    "def wrangle_saws():\n",
    "    '''This function will drop unnecessary columns, \n",
    "    create a 'location' using data acquired from \n",
    "    other columns, and melt the data to make month year column'''\n",
    "    # Reads the csv\n",
    "    saws = pd.read_csv('med_center_saws.csv')\n",
    "    # Removes NaN values from 'Prefix' and 'Suffix' column for concatenation in 'location'\n",
    "    saws['Prefix'] = saws.Prefix.fillna(value = '')\n",
    "    saws['Suffix'] = saws.Suffix.fillna(value = '')\n",
    "    # Concatenating columns together for specific location\n",
    "    saws['location'] = saws['Prefix'] + ' ' + saws['Service Location'] + ' ' + saws['Suffix']\n",
    "    # Stripping any extra whitespace\n",
    "    saws['location'] = saws.location.str.strip()\n",
    "    saws = saws.drop(columns=['Unnamed: 0', 'Prefix', 'Suffix', 'Service Location'])\n",
    "    saws = saws.melt(id_vars=['Record #', 'ZIP Code', 'location'], \n",
    "              var_name='Month & Year', value_name='Gallons Consumed')\n",
    "    saws = saws.set_index('Record #')\n",
    "    saws = saws.fillna(0)\n",
    "    saws = saws.rename(columns={\"ZIP Code\": \"zipcode\", 'Month & Year':'year_month', \n",
    "                                'Gallons Consumed':'gallons_consumed'})\n",
    "    # replace * with 0\n",
    "    saws = saws.replace(to_replace='*', value=0)\n",
    "    # change data type\n",
    "    saws['gallons_consumed'] = saws['gallons_consumed'].astype(int)\n",
    "\n",
    "    return fix_dates(saws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "saws = wrangle_saws()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 145776 entries, 274262 to 545921\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   zipcode           145776 non-null  int64         \n",
      " 1   location          145776 non-null  object        \n",
      " 2   year_month        145776 non-null  object        \n",
      " 3   gallons_consumed  145776 non-null  int64         \n",
      " 4   datetime          145776 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "saws.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>location</th>\n",
       "      <th>year_month</th>\n",
       "      <th>gallons_consumed</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Record #</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>274262</th>\n",
       "      <td>78229</td>\n",
       "      <td>ACCOLON DR</td>\n",
       "      <td>17-JAN</td>\n",
       "      <td>6733</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274263</th>\n",
       "      <td>78229</td>\n",
       "      <td>ACCOLON DR</td>\n",
       "      <td>17-JAN</td>\n",
       "      <td>5237</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274264</th>\n",
       "      <td>78229</td>\n",
       "      <td>ACCOLON DR</td>\n",
       "      <td>17-JAN</td>\n",
       "      <td>2992</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274265</th>\n",
       "      <td>78229</td>\n",
       "      <td>ACCOLON DR</td>\n",
       "      <td>17-JAN</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274266</th>\n",
       "      <td>78229</td>\n",
       "      <td>ACCOLON DR</td>\n",
       "      <td>17-JAN</td>\n",
       "      <td>4489</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          zipcode    location year_month  gallons_consumed   datetime\n",
       "Record #                                                             \n",
       "274262      78229  ACCOLON DR     17-JAN              6733 2017-01-01\n",
       "274263      78229  ACCOLON DR     17-JAN              5237 2017-01-01\n",
       "274264      78229  ACCOLON DR     17-JAN              2992 2017-01-01\n",
       "274265      78229  ACCOLON DR     17-JAN                 0 2017-01-01\n",
       "274266      78229  ACCOLON DR     17-JAN              4489 2017-01-01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saws.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saws.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
